---
published: true
title: 对话系统论文笔记十一:emotional dialog system
category: Dialogue System
tags: 
  - DL
  - DS
  - paper reading
layout: post
---

2019.12.5 更新 Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset 

2020.5.27 更新 GENERATING EMPATHETIC RESPONSES BY LOOKING AHEAD THE USER’S SENTIMENT

2020.10.29 更新 MOJITALK: Generating Emotional Responses at Scale Xianda

2020.11.2 更新 MoEL: Mixture of Empathetic Listeners

2020.11.2 更新 Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory

2020.11.2 更新 Generating Responses with a Specific Emotion in Dialog

2020.11.6 更新 Towards Persona-Based Empathetic Conversational Models

2020.11.6 更新 EmpGAN: Multi-resolution Interactive Empathetic Dialogue Generation

2020.11.10 更新 MIME: MIMicking Emotions for Empathetic Response Generation

# Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset

ACL 2019

## 总结

提出了一个新任务，如何让chatbot变得善解人意？基于数据训练出来的chatbot可能会很aggressive，或是理解不了对方谈话时的心情，比如在对话时，察觉到对方afraid/proud/faithful等情绪，应该产生对应的response，afraid就应该给予对方帮助，察觉到对面此时是proud就应该称赞等等。其实这个motivation我还觉得挺make sense的，这篇文章就基于此，提出了Empathetic的数据集和基于这个数据集的baseline。

2020.11.2 更新：这个数据集是长什么样子的？有什么特点？

# GENERATING EMPATHETIC RESPONSES BY LOOKING AHEAD THE USER’S SENTIMENT

ICASSP 2020

## 总结

以前的关注“sentiment"的对话系统研究有两种，第一种是提前给定emotion/emoji，生成对应回复；第二种是根据当前user的emotion做出不一样的回复（详情看上面那篇论文）。而这篇的作者认为第一种做法，提前给定的emotion不一定就是empathetic的，而第二种做法，如果不提前就设计好每种emotion state的回复机制，也不能产生empathetic的回复（这里我的理解可能有一点误差，因为原文也只是一句话，不好理解，并且我觉得这里有点牵强）。所以作者设计了一个Look-ahead的对话系统，具体做法是生成当前回复后，去预测当前回复的回复sentiment（即user对当前回复的sentiment，套娃？），根据此sentiment用RL去学习。

这一篇的大概思想我是懂的，但是实验部分未免太不清楚了，既然要去预测sentiment，为何没有去分析这个sentiment分类器的性能呢？而只是做了简单的automatic evaluation和human evaluation，我觉得这个sentiment不太能预测的出来，会有很大的误差。

# MOJITALK: Generating Emotional Responses at Scale Xianda

ACL 2018

## 总结

这篇文章的主要贡献点在于1.提出了一个公开的，基于emoji的（可视为对话带有emotion标签）的数据集 2.应用了2017年时候的SOTA训练了一个emotional的模型。这里的emotional主要指的是模型能够捕捉到target中的emotion信息，这里的模型还没有能力生成指定emotion label的回复。

【数据集】从Twitter上面收集了对话数据，进行了一系列的文本清洗，最后每句话都对应了一个emoji label。

【模型】1. Base模型，普通的基于attention的Seq2Seq，没啥好说的，将emoji embedding和encoder的hidden state做拼接。

2. CVAE模型，在普通CVAE模型的基础上，将emoji embedding和encoder的hidden state做拼接。
3. Reinforced CAVE，在第二个CVAE模型的基础上，训练了一个emotion分类器，用于预测生成回复的emotion label，并且有额外的emotion reward。

这个工作的主要贡献点还是在于dataset，后面有很多的工作都是基于这个Twitter-emoji数据集的。

# MoEL: Mixture of Empathetic Listeners

EMNLP-IJCNLP 2019

## 总结

以往的empathetic的对话系统可以分成两种，第一种是预测user说话时的emotion，再根据user的emotion生成empathetic的回复，这种方法一般是隐式的从ground-truth里去学习应该回复哪种emotion（模型设计者不需要知道此时此刻哪种emotion是empathetic的，而是让模型自己去学）；第二种是给定一个emotion，生成指定emotion的回复（模型设计者需要显式的给定现在的emotion，再让模型去生成）。作者认为，前者的问题在于，如果模型只有一个decoder的话，很难学到如何回复多种类型的emotion（需要对emotion进行细分，不同类型的emotion需要有不同的decoder）。后者的问题在于，很难知道什么样的emotion才是empathetic的。这个motivation其实有点问题，因为并不是数据集中的response就一定是empathetic的，也可能是toxic的回复，后者的优势在于能显式的对产生的response的emotion进行控制，而非让模型自己去学。

作者基于以上的motivation设计了一个multi-decoder的模型，模型分成三个部分：Emotion Tracker, Emotion Aware Listeners, Meta Listener，Emotion Tracker是一个transformer，接收context输出context vector，Emotion Aware Listeners包含n+1个Listener(1个shared listener和n个listeners)，Listener其实就是transformer decoder，将context vector和这些decoder的输出做处理(用的是key-value memory network)，最后每个decoder都有一个score，用来衡量此时应该选择的decoder，最后总的输出是hidden state的加权求和，而Meta Listener就是一个transformer decoder，生成最后的回复。模型的loss是MLE和选择listener的cross entropy。

作者在实验部分有对Emotion Aware Listeners的每个Listeners单独研究，在case study部分展示了一个例子，即每个Listeners对给定的input产生了不同emotion的回复。但我依然觉得这类的case study说服力不足，应该进行分析统计，而且这些Listener的名字应该是作者自己标的？在文章中也没有具体说明。

# Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory

AAAI 2018

## 总结

作者说这是在对话系统中第一篇考虑emotion因素的工作，并且提出了一个兼顾grammer和emotion的模型，即给定一个emotion category，生成指定emotion的回复。工作的一大难点在于缺少数据集，于是作者在NLPCC的一个微博数据集上训练了一个情感分类器，再用这个分类器在STC数据集（对话数据集）上对response进行预测，构建了一个包含response情感标签的对话数据集。

文章的贡献点在于1. 提出了新任务 2.设计了ECM来生成指定emotion的回复 3.做实验表明ECM的效果好。

说实话，这篇文章的model部分我有点没看懂，具体的细节感觉跟memory network很像，但是跟它前面的model overview部分又对应不上，太难了。不过可以看出来一点，现在的工作还没有关注到empathetic这一点，而是在说，给定一个input,不同的人就有不同的反应(emotion)。

# Generating Responses with a Specific Emotion in Dialog

ACL 2019

## 总结

这篇文章相当于上一篇AAAI2018的follow，motivation很接近，有一点不一样的是，作者指出来ECM会倾向于生成"emotion-generic"(自己瞎取的)的回复，就算显式的让模型去生成某个emotion的回复，模型还是倾向于生成那些有更多训练数据的回复。

【数据集】跟ECM一样，在NLPCC的数据集上训练一个classifier，然后在STC上做分类。

【模型】文章提出两种mechanism，一种是显式的，第二种是隐式的，先构建好一个emotion words词表，对于每个emotion label而言都有若干个比较重要的emotion words。

显式的方法是在生成指定emotion时，把此emotion对应的emotion words取出来和context vector以及decoder的hidden state做attention，最后取加权和，并且在decode的时候显式的区分出emotion words和generic words。

隐式的方法是在decode时，对于当前生成的word有一个特殊的emotion classification mechanism去算一个loss，其实就跟别人训练分类器后用分类的分数做reward有点像，但是这篇文章计算的方式不同，而且也不是用classifier，用的是expected word embedding（没去细看）。

在decode时作者有些小trick，有做消融实验来证明work。

【实验】自己提出了两个emotion的自动指标，一个是用classifier（构建数据集用的）打分，一个是统计emotion words的个数。

虽然在introduction部分作者有指出ECM的不足之处，但是我在model以及experiment部分都没看到这部分的分析，只有指标上的对比。

# Towards Persona-Based Empathetic Conversational Models

EMNLP 2020

## 总结

这篇文章的核心观点是：以往的empathetic对话系统往往都忽略了persona，然而，在生成empathetic回复时，persona是非常重要的信息，因为不同persona的人感到empathetic的点是不同的。作者做了一个小实验，统计了他自己构造的数据集PEC中两个不同人回复的TF-IDF相似度，和从数据集中任意挑选两个回复的TF-IDF相似度，实验表明，前者的相似度小于后者，这也就说明，不同的人产生的empathetic回复是不一样的。于是作者提出要将persona引入到empathetic回复生成的任务中，并且提出了自己的数据集PEC。

【数据集】PEC是在reddit的happy和offmychest两个subreddit话题下爬取的数据，作者认为在这两个subreddit下面的post和response包含了较多的情感信息，采用了一系列规则去提取说话者的persona, context和response。

【模型】本文的模型是retrieval型的，在用BERT做encoder分别得到context, persona, response的特征向量后，经过Hop-1 attention和Hop-2 attention，提取他们的关系，得到一个分数用于挑选candidates。

【实验】除了上面提到的相似度小实验和retrieval对话系统常规的自动指标之外，还有一个比较有趣的实验，作者构建了一个not-empathetic的闲聊数据集CASUAL（不包含太多情绪和情感），用PEC的数据去替换，发现替换的越多，结果就越好，作者说，这表明了persona在empathetic数据集上发挥了作用。

这篇的数据集虽说包含了很多的emotion，但是没有提供emotion标签，并且在模型部分，也没有显式的emotion words或者emotion label，所以这就是一个persona的对话模型模型在一个包含了很多emotion对话的数据集上做实验。文章写的其实挺好的，值得一读。

# EmpGAN: Multi-resolution Interactive Empathetic Dialogue Generation

AAAI 2020

## 总结

motivation有两个，第一个是以往的模型只关注sentence-level的emotion，第二个是以往的模型忽略的用户的feedback，文章基于此提出了multi-grainularity多粒度的模型，并且用GAN考虑到用户的feedback（类似于上面有一篇looking ahead)。

这篇文章我觉得motivation还算充分，但是与model并没有很好的对应，实验部分也没有亮点，我个人认为存在以下问题：

1. 数学符号混乱，在Empathetic generator这一节，出现了一些上下文根本没出现的数学符号，整个模型的叙述逻辑让人晕头转向。
2. 模型图混乱，VE是什么？为什么同样的特征向量在模型图中能在不同的地方出现三次？
3. Emotion words是怎么构建的？个人认为应该有个专门的小节放在模型部分解释Emotion words的construction。
4. motivation的word-level emotion在模型中是怎么体现的？emotion words吗？
5. 实验部分有对word-level emotion进行分析吗？

# MIME: MIMicking Emotions for Empathetic Response Generation 

EMNLP 2020

## 总结

以往的工作对每种emotion是“一视同仁”的，这篇文章提出要对emotion进行更加细粒度的区分，比如positive的emotion和negative的emotion就有很明显的差异，当察觉到user的emotion是positive时，生成的回复也应该时positive的，当察觉到user的emotion是negative时，生成的回复不仅要negative，但是也要带有某种正面性质的安慰，作者做的事情就是对positive和negative的emotion回复进行了区分。